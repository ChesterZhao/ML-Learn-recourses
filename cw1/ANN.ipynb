{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.Input Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e566f44fb9d65ee"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b75bb4de9908ad7",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:42.997096Z",
     "start_time": "2023-11-19T12:08:42.952732Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc2330d325cef25"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"erythema\", \"scaling\", \"definite borders\", \"itching\", \"koebner phenomenon\",\n",
    "    \"polygonal papules\", \"follicular papules\", \"oral mucosal involvement\", \"knee and elbow involvement\",\n",
    "    \"scalp involvement\", \"family history\", \"melanin incontinence\", \"eosinophils in the infiltrate\",\n",
    "    \"PNL infiltrate\", \"fibrosis of the papillary dermis\", \"exocytosis\", \"acanthosis\",\n",
    "    \"hyperkeratosis\", \"parakeratosis\", \"clubbing of the rete ridges\", \"elongation of the rete ridges\",\n",
    "    \"thinning of the suprapapillary epidermis\", \"spongiform pustule\", \"munro microabcess\",\n",
    "    \"focal hypergranulosis\", \"disappearance of the granular layer\", \"vacuolisation and damage of basal layer\",\n",
    "    \"spongiosis\", \"saw-tooth appearance of retes\", \"follicular horn plug\", \"perifollicular parakeratosis\",\n",
    "    \"inflammatory monoluclear inflitrate\", \"band-like infiltrate\", \"Age\", \"class\"\n",
    "]\n",
    "\n",
    "dermatology_data = pd.read_csv('dermatology/dermatology.data', header=None, names=column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.008831Z",
     "start_time": "2023-11-19T12:08:42.956117Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Data Preprocessing\n",
    "## 3.1 Data replace and fill missing values\n",
    "- Replace the missing values with NaN\n",
    "- Convert the 'Age' column to numeric\n",
    "- Fill the missing values in 'Age' with the median age\n",
    "- Drop the 'perifollicular parakeratosis' column(because all values are 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa9f28416dd28e2"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Replacing the missing values with NaN\n",
    "dermatology_data.replace(\"?\", pd.NA, inplace=True)\n",
    "dermatology_data['Age'] = pd.to_numeric(dermatology_data['Age'], errors='coerce')\n",
    "\n",
    "# Filling the missing values in 'Age' with the median age\n",
    "age_median = dermatology_data['Age'].median()\n",
    "dermatology_data['Age'].fillna(age_median, inplace=True)\n",
    "\n",
    "# Dropping the 'perifollicular parakeratosis' column\n",
    "dermatology_data.drop('perifollicular parakeratosis', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.009021Z",
     "start_time": "2023-11-19T12:08:42.983977Z"
    }
   },
   "id": "e4ca06310ab7db2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Data Scaling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12c008b690be4541"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "dermatology_data_scaled = dermatology_data.copy()\n",
    "for column in dermatology_data.columns[:-1]:  \n",
    "    col_min = dermatology_data[column].min()\n",
    "    col_max = dermatology_data[column].max()\n",
    "    dermatology_data_scaled[column] = (dermatology_data[column] - col_min) / (col_max - col_min)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.009901Z",
     "start_time": "2023-11-19T12:08:42.989206Z"
    }
   },
   "id": "c4c40237672db3c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Data Splitting\n",
    "- Split the data into features and target\n",
    "- One-hot encode the target, to get 6 output nodes\n",
    "- Split the data into train and test sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e64f64c483e5eb03"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaochengxin/anaconda3/envs/Learn/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the data into features and target\n",
    "X = dermatology_data_scaled.drop('class', axis=1).values\n",
    "y = dermatology_data_scaled['class'].values\n",
    "\n",
    "# One-hot encoding the target, to get 6 output nodes, it will more fit to train ANN model\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.012945Z",
     "start_time": "2023-11-19T12:08:43.002380Z"
    }
   },
   "id": "69c284527853f441"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. ANN Model\n",
    "## 4.1 Tools preparation\n",
    "- I choose use sigmoid as my activation function\n",
    "- I choose use cross-entropy as my loss function\n",
    "- Due to the output is multi-class, I choose use softmax as my activation function for output layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec15becfac5cfedf"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Design the Softmax activation function for the output layer\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Function to compute the loss using cross-entropy\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.sum(y_true * np.log(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.022288Z",
     "start_time": "2023-11-19T12:08:43.012204Z"
    }
   },
   "id": "851eded2265baecf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 ANN implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd4c1573625c20d8"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        - I choose use 2 layers ANN model, the first layer is hidden layer, the second layer is output layer. I used the random randn function to initialize the weights to get more accuracy and help the model to fitting the data better.\n",
    "        - For the bias, I used the zeros function to initialize the bias.\n",
    "        \"\"\"\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.bias1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "        self.bias2 = np.zeros((1, output_size))\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Forward pass\n",
    "        self.layer1 = sigmoid(np.dot(X, self.weights1) + self.bias1)\n",
    "        self.output = softmax(np.dot(self.layer1, self.weights2) + self.bias2)\n",
    "        return self.output\n",
    "\n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        # Backward pass\n",
    "        output_error = self.output - y\n",
    "        output_delta = output_error\n",
    "\n",
    "        layer1_error = output_delta.dot(self.weights2.T)\n",
    "        layer1_delta = layer1_error * sigmoid_derivative(self.layer1)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights2 -= self.layer1.T.dot(output_delta) * learning_rate\n",
    "        self.bias2 -= np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights1 -= X.T.dot(layer1_delta) * learning_rate\n",
    "        self.bias1 -= np.sum(layer1_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.feedforward(X)\n",
    "            self.backpropagation(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = cross_entropy_loss(y, self.output)\n",
    "                print(\"Epoch:\", epoch, \"Loss:\", loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.022515Z",
     "start_time": "2023-11-19T12:08:43.017616Z"
    }
   },
   "id": "cf8277b26ff69fbf"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1169.3902019077527\n",
      "Epoch: 100 Loss: 26.77995155969457\n",
      "Epoch: 200 Loss: 13.176791701519704\n",
      "Epoch: 300 Loss: 8.196715266703963\n",
      "Epoch: 400 Loss: 5.736662461762528\n",
      "Epoch: 500 Loss: 4.334646353586688\n",
      "Epoch: 600 Loss: 3.4431861991611816\n",
      "Epoch: 700 Loss: 2.830376220235971\n",
      "Epoch: 800 Loss: 2.3857392448008072\n",
      "Epoch: 900 Loss: 2.0502675909660284\n"
     ]
    }
   ],
   "source": [
    "# Creating the ANN\n",
    "ann = ANN(X_train.shape[1], 10, y_train.shape[1])\n",
    "\n",
    "# Training the ANN\n",
    "ann.train(X_train, y_train, epochs=1000, learning_rate=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.113174Z",
     "start_time": "2023-11-19T12:08:43.022213Z"
    }
   },
   "id": "4b100499488a9598"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.972972972972973"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to predict classes using the trained ANN\n",
    "def predict(X, model):\n",
    "    output = model.feedforward(X)\n",
    "    predictions = np.argmax(output, axis=1)\n",
    "    return predictions\n",
    "\n",
    "# Predicting classes on the test set\n",
    "y_pred = predict(X_test, ann)\n",
    "\n",
    "# Converting one-hot encoded test labels back to class labels for comparison\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = np.mean(y_pred == y_test_labels)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T12:08:43.118850Z",
     "start_time": "2023-11-19T12:08:43.114072Z"
    }
   },
   "id": "fdfa612859d3b7ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b75bb4de9908ad7",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.000088Z",
     "start_time": "2023-11-14T01:05:30.991989Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"erythema\", \"scaling\", \"definite borders\", \"itching\", \"koebner phenomenon\",\n",
    "    \"polygonal papules\", \"follicular papules\", \"oral mucosal involvement\", \"knee and elbow involvement\",\n",
    "    \"scalp involvement\", \"family history\", \"melanin incontinence\", \"eosinophils in the infiltrate\",\n",
    "    \"PNL infiltrate\", \"fibrosis of the papillary dermis\", \"exocytosis\", \"acanthosis\",\n",
    "    \"hyperkeratosis\", \"parakeratosis\", \"clubbing of the rete ridges\", \"elongation of the rete ridges\",\n",
    "    \"thinning of the suprapapillary epidermis\", \"spongiform pustule\", \"munro microabcess\",\n",
    "    \"focal hypergranulosis\", \"disappearance of the granular layer\", \"vacuolisation and damage of basal layer\",\n",
    "    \"spongiosis\", \"saw-tooth appearance of retes\", \"follicular horn plug\", \"perifollicular parakeratosis\",\n",
    "    \"inflammatory monoluclear inflitrate\", \"band-like infiltrate\", \"Age\", \"class\"\n",
    "]\n",
    "\n",
    "dermatology_data = pd.read_csv('dermatology/dermatology.data', header=None, names=column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.000356Z",
     "start_time": "2023-11-14T01:05:30.995969Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "dermatology_data.replace(\"?\", pd.NA, inplace=True)\n",
    "dermatology_data['Age'] = pd.to_numeric(dermatology_data['Age'], errors='coerce')\n",
    "\n",
    "# Fill the missing values in 'Age' with the median age\n",
    "age_median = dermatology_data['Age'].median()\n",
    "dermatology_data['Age'].fillna(age_median, inplace=True)\n",
    "\n",
    "dermatology_data.drop('perifollicular parakeratosis', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.004786Z",
     "start_time": "2023-11-14T01:05:31.000927Z"
    }
   },
   "id": "e4ca06310ab7db2d"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaochengxin/anaconda3/envs/Learn/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "((292, 33), (74, 33), (292, 6), (74, 6))"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dermatology_data_scaled = dermatology_data.copy()\n",
    "for column in dermatology_data.columns[:-1]:  # Exclude the class label for scaling\n",
    "    col_min = dermatology_data[column].min()\n",
    "    col_max = dermatology_data[column].max()\n",
    "    dermatology_data_scaled[column] = (dermatology_data[column] - col_min) / (col_max - col_min)\n",
    "\n",
    "X = dermatology_data_scaled.drop('class', axis=1).values\n",
    "y = dermatology_data_scaled['class'].values\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape of the training and test data\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.020621Z",
     "start_time": "2023-11-14T01:05:31.006325Z"
    }
   },
   "id": "69c284527853f441"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Softmax activation function for the output layer\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Function to compute the loss using cross-entropy\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.sum(y_true * np.log(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.023234Z",
     "start_time": "2023-11-14T01:05:31.021501Z"
    }
   },
   "id": "851eded2265baecf"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# ANN class\n",
    "class TwoLayerANN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.bias1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "        self.bias2 = np.zeros((1, output_size))\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Forward pass\n",
    "        self.layer1 = sigmoid(np.dot(X, self.weights1) + self.bias1)\n",
    "        self.output = softmax(np.dot(self.layer1, self.weights2) + self.bias2)\n",
    "        return self.output\n",
    "\n",
    "    def backpropagation(self, X, y, learning_rate):\n",
    "        # Backward pass\n",
    "        output_error = self.output - y\n",
    "        output_delta = output_error\n",
    "\n",
    "        layer1_error = output_delta.dot(self.weights2.T)\n",
    "        layer1_delta = layer1_error * sigmoid_derivative(self.layer1)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights2 -= self.layer1.T.dot(output_delta) * learning_rate\n",
    "        self.bias2 -= np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights1 -= X.T.dot(layer1_delta) * learning_rate\n",
    "        self.bias1 -= np.sum(layer1_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.feedforward(X)\n",
    "            self.backpropagation(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = cross_entropy_loss(y, self.output)\n",
    "                print(\"Epoch:\", epoch, \"Loss:\", loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.028125Z",
     "start_time": "2023-11-14T01:05:31.025353Z"
    }
   },
   "id": "cf8277b26ff69fbf"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 975.9841230520677\n",
      "Epoch: 100 Loss: 22.936869873981312\n",
      "Epoch: 200 Loss: 10.621595110967936\n",
      "Epoch: 300 Loss: 6.789306972459894\n",
      "Epoch: 400 Loss: 4.919639174035273\n",
      "Epoch: 500 Loss: 3.8086832462635196\n",
      "Epoch: 600 Loss: 3.073378751324366\n",
      "Epoch: 700 Loss: 2.5533008519717955\n",
      "Epoch: 800 Loss: 2.1683685198343134\n",
      "Epoch: 900 Loss: 1.8737067187691712\n"
     ]
    }
   ],
   "source": [
    "# ANN parameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 10  # Number of nodes in the hidden layer\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "# Creating the ANN\n",
    "ann = TwoLayerANN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Training the ANN\n",
    "ann.train(X_train, y_train, epochs=1000, learning_rate=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.121413Z",
     "start_time": "2023-11-14T01:05:31.029398Z"
    }
   },
   "id": "4b100499488a9598"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9864864864864865"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to predict classes using the trained ANN\n",
    "def predict(X, model):\n",
    "    output = model.feedforward(X)\n",
    "    predictions = np.argmax(output, axis=1)\n",
    "    return predictions\n",
    "\n",
    "# Predicting classes on the test set\n",
    "y_pred = predict(X_test, ann)\n",
    "\n",
    "# Converting one-hot encoded test labels back to class labels for comparison\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = np.mean(y_pred == y_test_labels)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T01:05:31.125034Z",
     "start_time": "2023-11-14T01:05:31.121891Z"
    }
   },
   "id": "fdfa612859d3b7ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
